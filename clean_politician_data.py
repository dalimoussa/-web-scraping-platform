"""
Data Cleaning Script - Remove Noise from Election Data
Filters out table headers, metadata, and non-name entries
"""

import pandas as pd
import re
from pathlib import Path

def is_valid_politician_name(name: str) -> bool:
    """
    Check if a name is a valid politician name.
    Returns False for table headers, metadata, and other noise.
    """
    
    if not name or pd.isna(name):
        return False
    
    name = str(name).strip()
    
    # Length check
    if len(name) < 2 or len(name) > 10:
        return False
    
    # Must contain Japanese characters
    if not re.search(r'[\u4e00-\u9fff\u3040-\u309f\u30a0-\u30ff]', name):
        return False
    
    # Exclude table headers and common metadata
    exclude_keywords = [
        # Table headers
        'æ°å', 'å†™çœŸ', 'æ€§åˆ¥', 'å…šæ´¾', 'æ–°æ—§', 'å¹´é½¢', 'å¾—ç¥¨',
        'ä¸»ãªè‚©æ›¸', 'è‚©æ›¸', 'æ‰€å±', 'å½“è½', 'çµæœ',
        
        # Metadata
        'åŸ·è¡Œç†ç”±', 'ä»»æœŸæº€äº†', 'é–¢é€£æƒ…å ±', 'é¸æŒ™æƒ…å ±',
        'æŠ•ç¥¨æ—¥', 'å‘Šç¤ºæ—¥', 'æŠ•ç¥¨ç‡', 'æœ‰æ¨©è€…', 'é–‹ç¥¨',
        'ä»¶', '/', 'ãƒšãƒ¼ã‚¸', 'ä¸€è¦§', 'çµæœ', 'é€Ÿå ±',
        
        # Prefecture/city names
        'éƒ½é“åºœçœŒ', 'å¸‚åŒºç”ºæ‘', 'åŒ—æµ·é“', 'é’æ£®çœŒ', 'å²©æ‰‹çœŒ',
        'å®®åŸçœŒ', 'ç§‹ç”°çœŒ', 'å±±å½¢çœŒ', 'ç¦å³¶çœŒ', 'èŒ¨åŸçœŒ',
        'æ ƒæœ¨çœŒ', 'ç¾¤é¦¬çœŒ', 'åŸ¼ç‰çœŒ', 'åƒè‘‰çœŒ', 'æ±äº¬éƒ½',
        'ç¥å¥ˆå·çœŒ', 'æ–°æ½ŸçœŒ', 'å¯Œå±±çœŒ', 'çŸ³å·çœŒ', 'ç¦äº•çœŒ',
        
        # Election types
        'é¸æŒ™', 'å¸‚é•·é¸', 'çŸ¥äº‹é¸', 'è­°å“¡é¸', 'ç”ºé•·é¸', 'æ‘é•·é¸',
        
        # Common non-name patterns
        'è©³ç´°', 'æƒ…å ±', 'å…¬å ±', 'ãƒ‡ãƒ¼ã‚¿', 'è¨˜äº‹', 'ç‰¹é›†',
        
        # Job titles that appear as separate entries
        'ä¼šç¤¾å“¡', 'ç„¡è·', 'çµŒå–¶', 'ä»£è¡¨', 'è·å“¡', 'å…ƒè·',
        'å‰è·', 'æ–°äºº', 'ç¾è·', 'ä¼šç¤¾å½¹å“¡', 'å›£ä½“è·å“¡',
        
        # Business/occupation descriptions (NEW - caught from data)
        'ä¼šç¤¾å–ç· å½¹', 'å–ç· å½¹', 'å…¬è¡†æµ´å ´æ¥­', 'æµ´å ´æ¥­',
        'æ•™å®¤ä¸»å®°', 'éŸ³æ¥½æ•™å®¤', 'å¡¾çµŒå–¶', 'åº—ä¸»',
        'è‡ªå–¶æ¥­', 'è¾²æ¥­', 'æ¼æ¥­', 'æ—æ¥­', 'å•†åº—ä¸»',
        'ä¼šç¤¾çµŒå–¶', 'å•†åº—çµŒå–¶', 'é£²é£Ÿåº—', 'ä¸å‹•ç”£',
        'å»ºè¨­æ¥­', 'è£½é€ æ¥­', 'é‹é€æ¥­', 'è²©å£²æ¥­',
        'ç†å®¹', 'ç¾å®¹', 'æ•´éª¨', 'æ¥éª¨', 'é¼ç¸',
        'ç¨ç†å£«', 'è¡Œæ”¿æ›¸å£«', 'å¸æ³•æ›¸å£«', 'å¼è­·å£«',
        'åŒ»å¸«', 'æ­¯ç§‘åŒ»', 'è–¬å‰¤å¸«', 'çœ‹è­·å¸«',
        'æ•™å“¡', 'è¬›å¸«', 'å¡¾é•·', 'æ ¡é•·', 'åœ’é•·',
        'åƒ§ä¾¶', 'ä½è·', 'å®®å¸', 'ç¥ä¸»',
        'è¾²å”', 'æ¼å”', 'å•†å·¥ä¼š', 'è¦³å…‰å”ä¼š',
        
        # Generic title patterns
        'ä¸»å®°', 'çµŒå–¶è€…', 'ä»£è¡¨è€…', 'ç†äº‹', 'ä¼šé•·', 'å‰¯ä¼šé•·',
        'é¡§å•', 'ç›¸è«‡å½¹', 'ç¤¾é•·', 'å°‚å‹™', 'å¸¸å‹™',
        'NPO', 'æ³•äºº', 'å”ä¼š', 'çµ„åˆ', 'é€£åˆä¼š'
    ]
    
    for keyword in exclude_keywords:
        if keyword in name:
            return False
    
    # Exclude if it looks like a date
    if re.search(r'\d{4}å¹´|\d+æœˆ|\d+æ—¥', name):
        return False
    
    # Exclude if it has too many numbers
    if len(re.findall(r'\d', name)) > 3:
        return False
    
    # Exclude entries with certain symbols/patterns
    if any(char in name for char in ['ï¼ˆ', 'ï¼‰', 'ã€', 'ã€‘', '/', 'ãƒ»ãƒ»', 'â€¦']):
        # Allow some punctuation for full names
        if name.count('ï¼ˆ') > 1 or name.count('ï¼‰') > 1:
            return False
    
    # Must look like a name (kanji/hiragana/katakana with possible space)
    # Typical Japanese name pattern: 2-5 characters, possibly with space
    if re.match(r'^[\u4e00-\u9fff\u3040-\u309f\u30a0-\u30ff\sã€€]+$', name):
        return True
    
    return False


def clean_politician_data(input_file: str, output_file: str):
    """Clean the politician data by removing noise."""
    
    print("\n" + "="*80)
    print("ğŸ§¹ DATA CLEANING - Removing Noise from Election Data")
    print("="*80 + "\n")
    
    # Read the CSV
    print(f"ğŸ“‚ Reading: {input_file}")
    df = pd.read_csv(input_file, encoding='utf-8')
    
    print(f"ğŸ“Š Original records: {len(df)}")
    
    # Filter valid names
    print("\nğŸ” Filtering valid politician names...")
    df['is_valid'] = df['name'].apply(is_valid_politician_name)
    
    valid_df = df[df['is_valid']].copy()
    noise_df = df[~df['is_valid']].copy()
    
    print(f"âœ… Valid politicians: {len(valid_df)} ({len(valid_df)/len(df)*100:.1f}%)")
    print(f"ğŸ—‘ï¸  Noise removed: {len(noise_df)} ({len(noise_df)/len(df)*100:.1f}%)")
    
    # Show some examples of removed noise
    print("\nğŸ“‹ Sample noise removed:")
    for i, name in enumerate(noise_df['name'].head(10), 1):
        print(f"  {i}. {name}")
    
    # Drop the helper column
    valid_df = valid_df.drop('is_valid', axis=1)
    
    # Additional cleaning
    print("\nğŸ”§ Additional cleaning...")
    
    # Remove exact duplicates
    before = len(valid_df)
    valid_df = valid_df.drop_duplicates(subset=['name', 'prefecture'], keep='first')
    after = len(valid_df)
    print(f"  â€¢ Removed {before - after} duplicate name+prefecture combinations")
    
    # Standardize party names
    party_mapping = {
        'è‡ªæ°‘': 'è‡ªç”±æ°‘ä¸»å…š',
        'ç«‹æ†²': 'ç«‹æ†²æ°‘ä¸»å…š',
        'å…¬æ˜': 'å…¬æ˜å…š',
        'å…±ç”£': 'å…±ç”£å…š',
        'ç¶­æ–°': 'æ—¥æœ¬ç¶­æ–°ã®ä¼š',
        'ç¤¾æ°‘': 'ç¤¾ä¼šæ°‘ä¸»å…š',
        'ã‚Œã„ã‚': 'ã‚Œã„ã‚æ–°é¸çµ„',
    }
    
    def standardize_party(party):
        if pd.isna(party) or party == '':
            return ''
        party = str(party).strip()
        for short, full in party_mapping.items():
            if short in party and full not in party:
                return full
        return party
    
    if 'party' in valid_df.columns:
        valid_df['party'] = valid_df['party'].apply(standardize_party)
        print(f"  â€¢ Standardized party names")
    
    # Sort by prefecture and name
    valid_df = valid_df.sort_values(['prefecture', 'name']).reset_index(drop=True)
    
    # Save cleaned data
    print(f"\nğŸ’¾ Saving cleaned data...")
    valid_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"âœ… Saved to: {output_file}")
    
    # Statistics
    print("\n" + "="*80)
    print("ğŸ“Š FINAL STATISTICS")
    print("="*80)
    print(f"\nâœ… Total valid politicians: {len(valid_df)}")
    
    # Top prefectures
    print("\nğŸ“ Top prefectures:")
    top_prefs = valid_df['prefecture'].value_counts().head(10)
    for pref, count in top_prefs.items():
        print(f"  â€¢ {pref}: {count} politicians")
    
    # Party distribution
    if 'party' in valid_df.columns:
        print("\nğŸ›ï¸  Party distribution:")
        parties = valid_df['party'].value_counts().head(10)
        for party, count in parties.items():
            if party:
                print(f"  â€¢ {party}: {count} politicians")
    
    # Data quality
    if 'party' in valid_df.columns:
        with_party = valid_df['party'].notna().sum()
        print(f"\nğŸ“ˆ Data quality:")
        print(f"  â€¢ With party: {with_party} ({with_party/len(valid_df)*100:.1f}%)")
    
    if 'status' in valid_df.columns:
        with_status = valid_df['status'].notna().sum()
        print(f"  â€¢ With election result: {with_status} ({with_status/len(valid_df)*100:.1f}%)")
    
    if 'election_date' in valid_df.columns:
        with_date = valid_df['election_date'].notna().sum()
        print(f"  â€¢ With election date: {with_date} ({with_date/len(valid_df)*100:.1f}%)")
    
    # Sample politicians
    print("\nğŸ“‹ Sample cleaned politicians:")
    for i, row in valid_df.head(10).iterrows():
        print(f"\n{i+1}. {row['name']}")
        if 'party' in row and row['party']:
            print(f"   Party: {row['party']}")
        if 'prefecture' in row:
            print(f"   Prefecture: {row['prefecture']}")
        if 'election' in row and pd.notna(row['election']):
            print(f"   Election: {row['election'][:50]}...")
        if 'status' in row and row['status']:
            print(f"   Result: {row['status']}")
    
    print("\n" + "="*80)
    print("âœ… DATA CLEANING COMPLETE!")
    print("="*80 + "\n")
    
    return valid_df


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Clean politician data")
    parser.add_argument('--input', '-i', default='politicians_from_elections.csv', help='Input CSV filename')
    parser.add_argument('--output', '-o', default='politicians_cleaned.csv', help='Output CSV filename')
    args = parser.parse_args()
    
    # Extract just filename if full path given
    from pathlib import Path
    input_file = f"data/outputs/{Path(args.input).name}"
    output_file = f"data/outputs/{Path(args.output).name}"
    
    clean_politician_data(input_file, output_file)
