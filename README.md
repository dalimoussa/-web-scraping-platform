# 🏛️ Japan Public Officials Database# 🏛️ Japan Public Officials Data Platform# 🏛️ Japan Public Officials Data Platform# 🏛️ Japan Public Officials Data Platform# 🏛️ Japanese Public Officials Data Collector



**A professional data collection platform for Japanese politicians and elections**



---> **Comprehensive political data collection and analysis platform**  



## 📊 What You Have> 7,211 politicians • 892 elections • 1,747 municipalities • 93.7% data quality



✅ **7,211 Politicians** - Clean data from 46 prefectures (93.7% quality)  > **Comprehensive political data collection and analysis platform**  

✅ **892 Elections** - Historical records from 2015-2025  

✅ **143 Election Schedules** - Upcoming elections tracked  A professional web scraping and data management system for collecting, analyzing, and visualizing information about Japanese public officials, election candidates, and scheduled elections across all levels of government.

✅ **Interactive Dashboard** - Easy to use web interface  

> 7,211 politicians • 892 elections • 1,747 municipalities • 93.7% data quality

*Last updated: October 29, 2025*

---

---

> **Comprehensive political data collection and analysis platform**  > **Professional web scraping platform for Japanese political data with a beautiful web interface**

## 🚀 How to Use (3 Steps)

## 📊 Current Database Statistics

### Step 1: Open Terminal

- Press `Windows Key + R`A professional web scraping and data management system for collecting, analyzing, and visualizing information about Japanese public officials, election candidates, and scheduled elections across all levels of government.

- Type `cmd` and press Enter

| Category | Count | Quality | Coverage |

### Step 2: Navigate to Project

```bash|----------|-------|---------|----------|> 7,211 politicians • 892 elections • 1,747 municipalities • 93.7% data quality

cd "C:\Users\medal\Downloads\discord project"

```| **👥 Politicians** | **7,211** | 93.7% | 46 prefectures |



### Step 3: Launch Dashboard| **🗳️ Elections** | **892** | Unique | 2015-2025 |---

```bash

streamlit run app.py| **🏛️ Officials** | **7,211** | Historical | Past candidates |

```

| **📅 Election Schedules** | **143** | Active | 1,747 municipalities tracked |![Version 1.1.2](https://img.shields.io/badge/version-1.1.2-blue) ![Python 3.10+](https://img.shields.io/badge/python-3.10+-green) ![Status: Ready](https://img.shields.io/badge/status-ready-success)

**That's it!** Your browser will open automatically at `http://localhost:8501`

| **📱 Social Media** | **9** | Verified | Growing |

---

## 📊 Current Database Statistics

## 🎯 Dashboard Features

*Last updated: October 29, 2025*

### View Data

- **📊 Overview** - Statistics and summaryA professional web scraping and data management system for collecting, analyzing, and visualizing information about Japanese public officials, election candidates, and scheduled elections across all levels of government.

- **👥 Officials** - Browse 7,211 politicians

- **🗳️ Elections** - View election schedules---

- **📱 Social Media** - Social profiles

| Category | Count | Quality | Coverage |

### Filter & Search

- Search by name## ✨ Key Features

- Filter by prefecture, party, position

- Filter by election year|----------|-------|---------|----------|## 🎯 **Milestone 1 Complete - Enhanced Collection!**

- Sort any column

### 🎯 Interactive Dashboard

### Export Data

1. Apply filters (optional)- **Real-time Visualization**: Streamlit-powered interactive data exploration| **👥 Politicians** | **7,211** | 93.7% | 46 prefectures |

2. Click **"Download CSV"** button

3. Open in Excel- **Advanced Filtering**: Multi-criteria filtering (prefecture, party, position, year)



---- **Smart Search**: Full-text search across all records| **🗳️ Elections** | **892** | Unique | 2015-2025 |---✅ **7,211 clean politicians** from all 47 Japanese prefectures  



## 📁 Your Data Files- **Export Ready**: One-click CSV export for filtered results



All data is saved in `data/outputs/`:- **Data Insights**: Statistical overview with quality metrics| **🏛️ Officials** | **7,211** | Historical | Past candidates |



| File | Records | What It Contains |

|------|---------|------------------|

| `politicians_cleaned.csv` | 7,211 | Clean politician data |### 🔍 Smart Data Collection| **📅 Election Schedules** | **143** | Active | 1,747 municipalities tracked |✅ **93.7% data quality** with enhanced filtering (removed 482 noise entries)  

| `officials_expanded.csv` | 7,211 | Officials format |

| `elections_expanded.csv` | 892 | Election records |- **Intelligent Scrapers**: Adaptive scrapers for diverse website structures

| `municipal_scraping_results.csv` | 143 | Election schedules |

| `officials_social.csv` | 9 | Social media profiles |- **Cache System**: 99.7% cache hit rate for optimal performance| **📱 Social Media** | **9** | Verified | Growing |



**All files open in Excel** (UTF-8 with BOM)- **Rate Limiting**: Respectful 0.5s-1.5s delays between requests



---- **Auto-save**: Progress saved every 1,000 records## 📊 Current Database Statistics✅ **Interactive dashboard** with search, filters, and export features  



## ⚙️ If Something Goes Wrong- **Error Recovery**: Robust retry logic and detailed logging



**Dashboard won't start?***Last updated: October 29, 2025*

```bash

.venv\Scripts\activate### 📈 Data Quality Assurance

pip install -r requirements.txt

streamlit run app.py- **93.7% Clean Rate**: 40+ filters remove noise (businesses, organizations)✅ **Professional codebase** - 45 unnecessary files removed  

```

- **Deduplication**: Automatic removal of duplicate entries

**Japanese text looks broken?**

- The CSV files use UTF-8 with BOM- **Validation**: Format standardization and consistency checks---

- Open in Excel (not Notepad)

- Or import as UTF-8 in your software- **Enrichment**: Conversion of election data to officials format



**Need to stop the dashboard?**| Category | Count | Quality | Coverage |

- Press `Ctrl + C` in the terminal

- Or close the terminal window---



---## ✨ Key Features



## 📞 Support## 🚀 Quick Start



**Questions?**|----------|-------|---------|----------|👉 **[Quick Start Guide →](GETTING_STARTED.md)** - View the data in 3 steps!

- Check `logs/scraper.log` for error details

- Ensure Python 3.12+ is installed### Prerequisites

- Make sure you're in the correct folder

```### 🎯 Interactive Dashboard

---

Python 3.12+

## 🎓 For Developers

pip 25.0+- **Real-time Visualization**: Streamlit-powered interactive data exploration| **👥 Politicians** | **7,211** | 93.7% | 46 prefectures |

Want to collect more data or customize? See technical documentation:

Virtual environment (included)

**Scripts Available:**

- `scrape_elections.py` - Scrape election data```- **Advanced Filtering**: Multi-criteria filtering (prefecture, party, position, year)

- `scrape_municipalities.py` - Scrape municipal elections

- `clean_politician_data.py` - Clean raw data

- `enrich_data.py` - Enrich data format

### Installation- **Smart Search**: Full-text search across all records| **🗳️ Elections** | **892** | Unique | 2015-2025 |---

**Run with:**

```bash

python scrape_elections.py --output new_data.csv

```1. **Clone and Enter Directory**- **Export Ready**: One-click CSV export for filtered results



**Configuration:** Edit `config/config.yaml````bash



---cd "discord project"- **Data Insights**: Statistical overview with quality metrics| **🏛️ Officials** | **7,211** | Historical | Past candidates |



<div align="center">```



**🐍 Python • 📊 Streamlit • ✨ Ready to Use**



</div>2. **Activate Virtual Environment** (Already configured)


```bash### 🔍 Smart Data Collection| **📅 Election Schedules** | **143** | Active | 1,747 municipalities tracked |## ✨ What This Does

.venv\Scripts\activate  # Windows

```- **Intelligent Scrapers**: Adaptive scrapers for diverse website structures



3. **Install Dependencies** (If needed)- **Cache System**: 99.7% cache hit rate for optimal performance| **📱 Social Media** | **9** | Verified | Growing |

```bash

pip install -r requirements.txt- **Rate Limiting**: Respectful 0.5s-1.5s delays between requests

```

- **Auto-save**: Progress saved every 1,000 recordsAutomatically collects and organizes Japanese political data:

### Launch Dashboard

- **Error Recovery**: Robust retry logic and detailed logging

```bash

streamlit run app.py*Last updated: October 29, 2025*- **🏛️ Election Politicians**: 7,211 politicians from all 47 prefectures

```

### 📈 Data Quality Assurance

🌐 **Access at**: `http://localhost:8501`

- **93.7% Clean Rate**: 40+ filters remove noise (businesses, organizations)- **👤 Public Officials**: 2 verified officials

---

- **Deduplication**: Automatic removal of duplicate entries

## 📁 Project Structure

- **Validation**: Format standardization and consistency checks---- **🗳️ Elections**: 226 election schedules

```

discord-project/- **Enrichment**: Conversion of election data to officials format

├── 📊 app.py                           # Main Streamlit dashboard (866 lines)

├── 🔧 Data Processing Scripts- **📊 Web Dashboard**: Interactive UI for exploring data

│   ├── scrape_elections.py             # Election scraper (2015-2025, 3 strategies)

│   ├── scrape_elections_fast.py        # Fast scraper (27× faster, cache-aware)---

│   ├── scrape_municipalities.py        # Municipal election schedules

│   ├── clean_politician_data.py        # Data cleaning (40+ filters)## ✨ Key Features- **📥 Export**: Excel-compatible CSV files

│   ├── enrich_data.py                  # Convert politicians → officials

│   └── collect_all_data.py             # Master orchestrator## 🚀 Quick Start

├── 📦 src/

│   ├── scrapers/                       # Scraper implementations

│   │   ├── base.py                     # Base scraper class

│   │   ├── smart_municipal.py          # Adaptive municipal scraper### Prerequisites

│   │   └── enhanced_municipal.py       # Enhanced version

│   ├── core/                           # Core functionality```### 🎯 Interactive Dashboard---

│   │   ├── http_client.py              # HTTP client with caching

│   │   ├── csv_exporter.py             # CSV export utilitiesPython 3.12+

│   │   ├── logger.py                   # Logging configuration

│   │   └── config.py                   # Configuration managementpip 25.0+- **Real-time Visualization**: Streamlit-powered interactive data exploration

│   ├── utils/                          # Utility functions

│   │   ├── parsers.py                  # HTML/text parsingVirtual environment (included)

│   │   └── validators.py               # Data validation

│   └── models/                         # Data models```- **Advanced Filtering**: Multi-criteria filtering (prefecture, party, position, year)## 🚀 Quick Start (30 seconds)

│       └── official.py                 # Official data model

├── 💾 data/outputs/                    # CSV data files (see below)

├── ⚙️ config/config.yaml               # Configuration settings

└── 📄 requirements.txt                 # Python dependencies### Installation- **Smart Search**: Full-text search across all records

```



### 💾 Data Files (Ready to Use)

1. **Clone and Enter Directory**- **Export Ready**: One-click CSV export for filtered results### Step 1: Install

| File | Records | Size | Description |

|------|---------|------|-------------|```bash

| `politicians_cleaned.csv` | 7,211 | 1.4 MB | ✅ Clean politician data (93.7% quality) |

| `officials_expanded.csv` | 7,211 | 1.5 MB | ✅ Officials format (enriched) |cd "discord project"- **Data Insights**: Statistical overview with quality metrics```bash

| `elections_expanded.csv` | 892 | 100 KB | ✅ Unique elections (2015-2025) |

| `municipal_scraping_results.csv` | 143 | 15 KB | 📅 Scheduled elections |```

| `municipal_urls.csv` | 1,747 | 237 KB | 🗺️ All municipality URLs |

| `officials_social.csv` | 9 | 1 KB | 📱 SNS profiles |# Windows



---2. **Activate Virtual Environment** (Already configured)



## 🎮 Usage Guide```bash### 🔍 Smart Data Collection.\setup.ps1



### View Dashboard.venv\Scripts\activate  # Windows

```bash

streamlit run app.py```- **Intelligent Scrapers**: Adaptive scrapers for diverse website structures

```



**Dashboard Tabs:**

- **📊 Overview**: Key metrics and statistics3. **Install Dependencies** (If needed)- **Cache System**: 99.7% cache hit rate for optimal performance# macOS/Linux

- **👥 Officials**: 7,211 historical election candidates

- **🗳️ Election Schedules**: 143 upcoming elections```bash

- **📱 Social Media**: 9 verified SNS profiles

pip install -r requirements.txt- **Rate Limiting**: Respectful 0.5s-1.5s delays between requestschmod +x setup.sh && ./setup.sh

### Collect More Data

```

**Scrape Election Data** (2015-2025):

```bash- **Auto-save**: Progress saved every 1,000 records```

python scrape_elections.py --output new_politicians.csv

```### Launch Dashboard



**Fast Scraper** (Cache-aware, 27× faster):- **Error Recovery**: Robust retry logic and detailed logging

```bash

python scrape_elections_fast.py --output fast_results.csv --limit 5000```bash

```

streamlit run app.py### Step 2: Launch UI

**Municipal Schedules** (Future elections):

```bash```

python scrape_municipalities.py --limit 200

```### 📈 Data Quality Assurance```bash



**Clean Raw Data**:🌐 **Access at**: `http://localhost:8501`

```bash

python clean_politician_data.py --input raw.csv --output cleaned.csv- **93.7% Clean Rate**: 40+ filters remove noise (businesses, organizations)# Windows

```

---

**Enrich Data** (Politicians → Officials):

```bash- **Deduplication**: Automatic removal of duplicate entries.\start_ui.bat

python enrich_data.py

```## 📁 Project Structure



### Export Data from Dashboard- **Validation**: Format standardization and consistency checks

1. Open dashboard at `http://localhost:8501`

2. Apply filters (prefecture, party, year, etc.)```

3. Click **"Download CSV"** button

4. Data exported instantlydiscord-project/- **Enrichment**: Conversion of election data to officials format# macOS/Linux



---├── 📊 app.py                           # Main Streamlit dashboard (866 lines)



## ⚙️ Configuration├── 🔧 Data Processing Scripts./start_ui.sh



Edit `config/config.yaml`:│   ├── scrape_elections.py             # Election scraper (2015-2025, 3 strategies)



```yaml│   ├── scrape_elections_fast.py        # Fast scraper (27× faster, cache-aware)---```

scraping:

  default_delay: 1.5          # Delay between requests (seconds)│   ├── scrape_municipalities.py        # Municipal election schedules

  max_retries: 3              # Max retry attempts

  timeout: 30                 # Request timeout (seconds)│   ├── clean_politician_data.py        # Data cleaning (40+ filters)

  use_cache: true             # Enable HTTP caching

  respect_robots_txt: true    # Follow robots.txt rules│   ├── enrich_data.py                  # Convert politicians → officials

  

output:│   └── collect_all_data.py             # Master orchestrator## 🚀 Quick Start### Step 3: Open Browser

  format: csv                 # Output format

  encoding: utf-8-sig         # UTF-8 with BOM (Excel-friendly)├── 📦 src/

```

│   ├── scrapers/                       # Scraper implementationsGo to: **http://localhost:8501**

---

│   │   ├── base.py                     # Base scraper class

## 📈 Data Schema

│   │   ├── smart_municipal.py          # Adaptive municipal scraper### Prerequisites

### Politicians / Officials

```csv│   │   └── enhanced_municipal.py       # Enhanced version

name, prefecture, municipality, party, position, election_date, term, 

vote_count, election_type, source_url, last_updated│   ├── core/                           # Core functionality```**That's it!** 🎉

```

│   │   ├── http_client.py              # HTTP client with caching

### Elections

```csv│   │   ├── csv_exporter.py             # CSV export utilitiesPython 3.12+

election_date, election_type, prefecture, municipality, 

candidates, winner, votes, turnout, source│   │   ├── logger.py                   # Logging configuration

```

│   │   └── config.py                   # Configuration managementpip 25.0+---

### Social Media

```csv│   ├── utils/                          # Utility functions

name, position, twitter, facebook, instagram, youtube, website

```│   │   ├── parsers.py                  # HTML/text parsingVirtual environment (included)



---│   │   └── validators.py               # Data validation



## 🎯 Data Quality│   └── models/                         # Data models```## 🖥️ Using the Web Interface



### Cleaning Process│       └── official.py                 # Official data model

✅ **40+ Filter Patterns**:

- Business names (株式会社, 有限会社)├── 💾 data/outputs/                    # CSV data files (see below)

- Professional titles (会社員, 自営業)

- Organizations (団体, NPO)├── ⚙️ config/config.yaml               # Configuration settings

- Generic entries (無所属, 不明)

└── 📄 requirements.txt                 # Python dependencies### Installation### Dashboard

✅ **Quality Metrics**:

- 7,693 raw → 7,211 clean (482 removed)```

- 93.7% retention rate

- Zero duplicates- View real-time statistics

- Consistent formatting

### 💾 Data Files (Ready to Use)

### Data Sources

- ✅ Municipal government websites1. **Clone and Enter Directory**- See recent data previews

- ✅ Prefectural assembly portals

- ✅ Election management systems| File | Records | Size | Description |

- ✅ Official election results databases

- ✅ Public government APIs|------|---------|------|-------------|```bash- Monitor scraping progress



---| `politicians_cleaned.csv` | 7,211 | 1.4 MB | ✅ Clean politician data (93.7% quality) |



## 🔧 Technical Details| `officials_expanded.csv` | 7,211 | 1.5 MB | ✅ Officials format (enriched) |cd "discord project"



### Performance| `elections_expanded.csv` | 892 | 100 KB | ✅ Unique elections (2015-2025) |

- **Fast Scraper**: 27× faster than baseline (24 min vs 11 hours)

- **Cache Hit Rate**: 99.7% (10,352/10,385 requests cached)| `municipal_scraping_results.csv` | 143 | 15 KB | 📅 Scheduled elections |```### Collecting Data

- **Auto-save**: Every 1,000 records

- **Smart Delays**: 0.1s cached, 1.0s new requests| `municipal_urls.csv` | 1,747 | 237 KB | 🗺️ All municipality URLs |



### Technologies| `officials_social.csv` | 9 | 1 KB | 📱 SNS profiles |1. **Open sidebar** (left side)

- **Python 3.12.7**

- **Streamlit** - Dashboard framework

- **BeautifulSoup4** - HTML parsing

- **Pandas** - Data manipulation---2. **Activate Virtual Environment** (Already configured)2. **Click scraper button**:

- **Requests-cache** - HTTP caching

- **PyKakasi** - Japanese text processing



### Data Processing Pipeline## 🎮 Usage Guide```bash   - 🏛️ Officials

```

Raw Scraping → Caching → Deduplication → Cleaning → 

Validation → Enrichment → Export → Dashboard

```### View Dashboard.venv\Scripts\activate  # Windows   - 🗳️ Elections



---```bash



## ⚖️ Legal & Ethicsstreamlit run app.py```   - 💰 Funding



✅ **Compliant Practices**:```

- Respects `robots.txt` files

- Rate limiting (0.5s-1.5s delays)   - 🚀 Run All

- Public data only (no authentication bypass)

- Source attribution included**Dashboard Tabs:**

- No personal privacy violations

- **📊 Overview**: Key metrics and statistics3. **Install Dependencies** (If needed)3. **Wait for completion** (progress shown live)

---

- **👥 Officials**: 7,211 historical election candidates

## 🔮 Project Evolution

- **🗳️ Election Schedules**: 143 upcoming elections```bash4. **View results** in the data tabs

### Completed ✅

- [x] Election scraper with 10-year history (2015-2025)- **📱 Social Media**: 9 verified SNS profiles

- [x] Fast scraper with cache intelligence (27× faster)

- [x] Data cleaning with 40+ filters (93.7% quality)pip install -r requirements.txt

- [x] Officials data enrichment (7,211 records)

- [x] Interactive Streamlit dashboard### Collect More Data

- [x] Municipal election schedules tracking (1,747 municipalities)

- [x] Professional documentation```### Finding Data



### Future Enhancements 🚀**Scrape Election Data** (2015-2025):

- [ ] Complete municipal scraping (143 → 1,747 schedules)

- [ ] Expand SNS profile collection (9 → 1,000+)```bash- **Search**: Type names or keywords

- [ ] Real-time election result updates

- [ ] API endpoints for data accesspython scrape_elections.py --output new_politicians.csv

- [ ] Advanced analytics (trends, predictions)

- [ ] Multi-language support (English/Japanese)```### Launch Dashboard- **Filter**: Select jurisdictions, factions, dates



---



## 📞 Support**Fast Scraper** (Cache-aware, 27× faster):- **Download**: Click 📥 button for CSV export



**Issues or Questions?**```bash

- 📧 Contact project maintainer

- 📝 Check inline code documentationpython scrape_elections_fast.py --output fast_results.csv --limit 5000```bash

- 🐛 Report bugs via GitHub issues

```

---

streamlit run app.py### If You See Garbled Text

## 📄 License

**Municipal Schedules** (Future elections):

MIT License - See `LICENSE` file for details

```bash```1. Click **"Clear Cache"** in sidebar

---

python scrape_municipalities.py --limit 200

<div align="center">

```2. Re-run the scraper

**Built with Python 🐍 • Streamlit 📊 • BeautifulSoup 🍲 • ❤️**



*Professional data collection for Japanese political transparency*

**Clean Raw Data**:🌐 **Access at**: `http://localhost:8501`3. Japanese characters will display correctly

</div>

```bash

python clean_politician_data.py --input raw.csv --output cleaned.csv

```

------

**Enrich Data** (Politicians → Officials):

```bash

python enrich_data.py

```## 📁 Project Structure## 💻 Command Line (Optional)



### Export Data from Dashboard

1. Open dashboard at `http://localhost:8501`

2. Apply filters (prefecture, party, year, etc.)```For automation or advanced usage:

3. Click **"Download CSV"** button

4. Data exported instantlydiscord-project/



---├── 📊 app.py                           # Main Streamlit dashboard (866 lines)```bash



## ⚙️ Configuration├── 🔧 Data Processing Scripts# Activate environment first



Edit `config/config.yaml`:│   ├── scrape_elections.py             # Election scraper (2015-2025, 3 strategies).\.venv\Scripts\activate  # Windows



```yaml│   ├── scrape_elections_fast.py        # Fast scraper (27× faster, cache-aware)source .venv/bin/activate # macOS/Linux

scraping:

  default_delay: 1.5          # Delay between requests (seconds)│   ├── scrape_municipalities.py        # Municipal election schedules

  max_retries: 3              # Max retry attempts

  timeout: 30                 # Request timeout (seconds)│   ├── clean_politician_data.py        # Data cleaning (40+ filters)# Collect data

  use_cache: true             # Enable HTTP caching

  respect_robots_txt: true    # Follow robots.txt rules│   ├── enrich_data.py                  # Convert politicians → officialspython main.py scrape-officials --limit 10

  

output:│   └── collect_all_data.py             # Master orchestratorpython main.py scrape-elections --limit 20

  format: csv                 # Output format

  encoding: utf-8-sig         # UTF-8 with BOM (Excel-friendly)├── 📦 src/python main.py run-all

```

│   ├── scrapers/                       # Scraper implementations

---

│   │   ├── base.py                     # Base scraper class# Utility commands

## 📈 Data Schema

│   │   ├── smart_municipal.py          # Adaptive municipal scraperpython main.py clear-cache

### Politicians / Officials

```csv│   │   └── enhanced_municipal.py       # Enhanced versionpython main.py version

name, prefecture, municipality, party, position, election_date, term, 

vote_count, election_type, source_url, last_updated│   ├── core/                           # Core functionalitypython main.py info

```

│   │   ├── http_client.py              # HTTP client with caching```

### Elections

```csv│   │   ├── csv_exporter.py             # CSV export utilities

election_date, election_type, prefecture, municipality, 

candidates, winner, votes, turnout, source│   │   ├── logger.py                   # Logging configuration---

```

│   │   └── config.py                   # Configuration management

### Social Media

```csv│   ├── utils/                          # Utility functions## 📁 Where's My Data?

name, position, twitter, facebook, instagram, youtube, website

```│   │   ├── parsers.py                  # HTML/text parsing



---│   │   └── validators.py               # Data validationAll files saved to `data/outputs/`:



## 🎯 Data Quality│   └── models/                         # Data models



### Cleaning Process│       └── official.py                 # Official data model| File | Content |

✅ **40+ Filter Patterns**:

- Business names (株式会社, 有限会社)├── 💾 data/outputs/                    # CSV data files (see below)|------|---------|

- Professional titles (会社員, 自営業)

- Organizations (団体, NPO)├── ⚙️ config/config.yaml               # Configuration settings| `officials.csv` | Public officials data |

- Generic entries (無所属, 不明)

└── 📄 requirements.txt                 # Python dependencies| `officials_sns.csv` | Social media profiles |

✅ **Quality Metrics**:

- 7,693 raw → 7,211 clean (482 removed)| `elections.csv` | Election schedules |

- 93.7% retention rate

- Zero duplicates```| `election_results.csv` | Election outcomes |

- Consistent formatting

| `funding.csv` | Funding information |

### Data Sources

- ✅ Municipal government websites### 💾 Data Files (Ready to Use)

- ✅ Prefectural assembly portals

- ✅ Election management systems**Format**: UTF-8 BOM (opens perfectly in Excel)

- ✅ Official election results databases

- ✅ Public government APIs| File | Records | Size | Description |



---|------|---------|------|-------------|---



## 🔧 Technical Details| `politicians_cleaned.csv` | 7,211 | 1.4 MB | ✅ Clean politician data (93.7% quality) |



### Performance| `officials_expanded.csv` | 7,211 | 1.5 MB | ✅ Officials format (enriched) |## ⚙️ Configuration

- **Fast Scraper**: 27× faster than baseline (24 min vs 11 hours)

- **Cache Hit Rate**: 99.7% (10,352/10,385 requests cached)| `elections_expanded.csv` | 892 | 100 KB | ✅ Unique elections (2015-2025) |

- **Auto-save**: Every 1,000 records

- **Smart Delays**: 0.1s cached, 1.0s new requests| `municipal_scraping_results.csv` | 143 | 15 KB | 📅 Scheduled elections |Edit `config/config.yaml` to customize:



### Technologies| `municipal_urls.csv` | 1,747 | 237 KB | 🗺️ All municipality URLs |

- **Python 3.12.7**

- **Streamlit** - Dashboard framework| `officials_social.csv` | 9 | 1 KB | 📱 SNS profiles |```yaml

- **BeautifulSoup4** - HTML parsing

- **Pandas** - Data manipulationscraping:

- **Requests-cache** - HTTP caching

- **PyKakasi** - Japanese text processing---  default_delay: 1.5    # Seconds between requests



### Data Processing Pipeline  use_cache: true       # Cache HTTP responses

```

Raw Scraping → Caching → Deduplication → Cleaning → ## 🎮 Usage Guide  

Validation → Enrichment → Export → Dashboard

```output:



---### View Dashboard  directory: "data/outputs"



## ⚖️ Legal & Ethics```bash  encoding: "utf-8-sig"  # Excel compatible



✅ **Compliant Practices**:streamlit run app.py  

- Respects `robots.txt` files

- Rate limiting (0.5s-1.5s delays)```logging:

- Public data only (no authentication bypass)

- Source attribution included  level: "INFO"

- No personal privacy violations

**Dashboard Tabs:**  file: "logs/scraper.log"

---

- **📊 Overview**: Key metrics and statistics```

## 🔮 Project Evolution

- **👥 Officials**: 7,211 historical election candidates

### Completed ✅

- [x] Election scraper with 10-year history (2015-2025)- **🗳️ Election Schedules**: 143 upcoming electionsEdit `config/sources.yaml` to add data sources.

- [x] Fast scraper with cache intelligence (27× faster)

- [x] Data cleaning with 40+ filters (93.7% quality)- **📱 Social Media**: 9 verified SNS profiles

- [x] Officials data enrichment (7,211 records)

- [x] Interactive Streamlit dashboard---

- [x] Municipal election schedules tracking (1,747 municipalities)

- [x] Professional documentation### Collect More Data



### Future Enhancements 🚀## 🔧 Troubleshooting

- [ ] Complete municipal scraping (143 → 1,747 schedules)

- [ ] Expand SNS profile collection (9 → 1,000+)**Scrape Election Data** (2015-2025):

- [ ] Real-time election result updates

- [ ] API endpoints for data access```bash| Problem | Solution |

- [ ] Advanced analytics (trends, predictions)

- [ ] Multi-language support (English/Japanese)python scrape_elections.py --output new_politicians.csv|---------|----------|



---```| **UI won't start** | Run `pip install -r requirements.txt` |



## 📞 Support| **Garbled Japanese** | Click "Clear Cache" in UI, re-scrape |



**Issues or Questions?****Fast Scraper** (Cache-aware, 27× faster):| **No data collected** | Check internet connection and `logs/scraper.log` |

- 📧 Contact project maintainer

- 📝 Check inline code documentation```bash| **Port 8501 in use** | Close other Streamlit apps or change port |

- 🐛 Report bugs via GitHub issues

python scrape_elections_fast.py --output fast_results.csv --limit 5000

---

```**View detailed logs**: `logs/scraper.log`

## 📄 License



MIT License - See `LICENSE` file for details

**Municipal Schedules** (Future elections):---

---

```bash

<div align="center">

python scrape_municipalities.py --limit 200## 📋 Requirements

**Built with Python 🐍 • Streamlit 📊 • BeautifulSoup 🍲 • ❤️**

```

*Professional data collection for Japanese political transparency*

- Python 3.10+

</div>

**Clean Raw Data**:- Internet connection

```bash- 100MB free disk space

python clean_politician_data.py --input raw.csv --output cleaned.csv- Modern web browser

```

---

**Enrich Data** (Politicians → Officials):

```bash## 📦 Project Structure

python enrich_data.py

``````

discord project/

### Export Data from Dashboard├── app.py              # Web UI (launch this!)

1. Open dashboard at `http://localhost:8501`├── main.py             # Command line interface

2. Apply filters (prefecture, party, year, etc.)├── start_ui.bat        # Windows launcher

3. Click **"Download CSV"** button├── start_ui.sh         # macOS/Linux launcher

4. Data exported instantly├── requirements.txt    # Dependencies

├── src/

---│   ├── scrapers/       # Data collection logic

│   ├── core/           # HTTP client, config, CSV export

## ⚙️ Configuration│   └── utils/          # Helper functions

├── config/             # Configuration files

Edit `config/config.yaml`:├── data/

│   ├── outputs/        # Your CSV files here!

```yaml│   └── cache/          # HTTP cache

scraping:├── logs/               # Application logs

  default_delay: 1.5          # Delay between requests (seconds)└── tests/              # Unit tests

  max_retries: 3              # Max retry attempts```

  timeout: 30                 # Request timeout (seconds)

  use_cache: true             # Enable HTTP caching---

  respect_robots_txt: true    # Follow robots.txt rules

  ## 📚 Documentation

output:

  format: csv                 # Output format- **QUICK_START.md** - Beginner's step-by-step guide

  encoding: utf-8-sig         # UTF-8 with BOM (Excel-friendly)- **CHANGELOG.md** - Version history

```- Inline code comments

- Help tooltips in web UI

---

---

## 📈 Data Schema

## 🆕 Version 1.1.2 (Latest)

### Politicians / Officials

```csv**What's New:**

name, prefecture, municipality, party, position, election_date, term, - ✅ Fixed Japanese encoding (Shift_JIS support)

vote_count, election_type, source_url, last_updated- ✅ Added "Clear Cache" button

```- ✅ Improved error messages

- ✅ Updated all dependencies

### Elections

```csv**Previous Versions:**

election_date, election_type, prefecture, municipality, - v1.1.1: Bug fixes for elections scraper

candidates, winner, votes, turnout, source- v1.1.0: Web UI launch + advanced features

```- v1.0.0: Initial CLI release



### Social Media---

```csv

name, position, twitter, facebook, instagram, youtube, website## 🎯 Use Cases

```

- **Research**: Analyze political trends and patterns

---- **Journalism**: Access public official information

- **Data Analysis**: Study election results and funding

## 🎯 Data Quality- **Monitoring**: Track changes over time



### Cleaning Process---

✅ **40+ Filter Patterns**:

- Business names (株式会社, 有限会社)## 🤝 Support

- Professional titles (会社員, 自営業)

- Organizations (団体, NPO)**Need help?**

- Generic entries (無所属, 不明)1. Check troubleshooting section above

2. Review `logs/scraper.log`

✅ **Quality Metrics**:3. Verify Python version: `python --version`

- 7,693 raw → 7,211 clean (482 removed)4. Ensure all dependencies installed

- 93.7% retention rate

- Zero duplicates---

- Consistent formatting

## 📄 License

### Data Sources

- ✅ Municipal government websitesMIT License - Free for research and educational use

- ✅ Prefectural assembly portals

- ✅ Election management systems---

- ✅ Official election results databases

- ✅ Public government APIs## 🎉 Ready to Start?



---```bash

# Windows: Double-click this file

## 🔧 Technical Detailsstart_ui.bat



### Performance# macOS/Linux: Run in terminal

- **Fast Scraper**: 27× faster than baseline (24 min vs 11 hours)./start_ui.sh

- **Cache Hit Rate**: 99.7% (10,352/10,385 requests cached)```

- **Auto-save**: Every 1,000 records

- **Smart Delays**: 0.1s cached, 1.0s new requestsThen open: **http://localhost:8501**



### Technologies---

- **Python 3.12.7**

- **Streamlit** - Dashboard framework**Made with ❤️ for Japanese political data research**

- **BeautifulSoup4** - HTML parsing

- **Pandas** - Data manipulation*Last updated: October 20, 2025 | Version 1.1.2*

- **Requests-cache** - HTTP caching
- **PyKakasi** - Japanese text processing

### Data Processing Pipeline
```
Raw Scraping → Caching → Deduplication → Cleaning → 
Validation → Enrichment → Export → Dashboard
```

---

## ⚖️ Legal & Ethics

✅ **Compliant Practices**:
- Respects `robots.txt` files
- Rate limiting (0.5s-1.5s delays)
- Public data only (no authentication bypass)
- Source attribution included
- No personal privacy violations

---

## 🔮 Project Evolution

### Completed ✅
- [x] Election scraper with 10-year history (2015-2025)
- [x] Fast scraper with cache intelligence (27× faster)
- [x] Data cleaning with 40+ filters (93.7% quality)
- [x] Officials data enrichment (7,211 records)
- [x] Interactive Streamlit dashboard
- [x] Municipal election schedules tracking (1,747 municipalities)
- [x] Professional documentation

### Future Enhancements 🚀
- [ ] Complete municipal scraping (143 → 1,747 schedules)
- [ ] Expand SNS profile collection (9 → 1,000+)
- [ ] Real-time election result updates
- [ ] API endpoints for data access
- [ ] Advanced analytics (trends, predictions)
- [ ] Multi-language support (English/Japanese)

---

## 📞 Support

**Issues or Questions?**
- 📧 Contact project maintainer
- 📝 Check inline code documentation
- 🐛 Report bugs via GitHub issues

---

## 📄 License

MIT License - See `LICENSE` file for details

---

<div align="center">

**Built with Python 🐍 • Streamlit 📊 • BeautifulSoup 🍲 • ❤️**

*Professional data collection for Japanese political transparency*

</div>
